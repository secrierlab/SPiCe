{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN model to model MERFISH data \n",
    "\n",
    "Note: figure code found in figures_paper_gnn.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "env: use base_env_gnn.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from src.config import *  \n",
    "from src.dataset import MouseSpatialPyg\n",
    "from src.models import Net\n",
    "from src.train import train_and_evaluate_model, binary_auc\n",
    "from src.explanations import *\n",
    "# Load merfish data\n",
    "merfish_data = pd.read_csv(\"data/merfish_dataset.csv\", index_col=0)\n",
    "\n",
    "# Preprocessing steps (e.g., filter cell types, remove low-count types)\n",
    "cell_types = merfish_data['Cell_Type'].unique()\n",
    "unique, counts = np.unique(merfish_data['Cell_Type'], return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "cell_types_to_remove = counts[counts < 1000]\n",
    "cell_types = [x for x in cell_types if x not in cell_types_to_remove]\n",
    "\n",
    "# Parameters\n",
    "#set this >100 for most accurate node explanations\n",
    "no_explan = 150\n",
    "epoch = 1000\n",
    "auc_records = []\n",
    "num_splits = 1\n",
    "just_explan = True\n",
    "\n",
    "for cell_type in tqdm(cell_types):\n",
    "    print(f\"Processing cell type: {cell_type}\")\n",
    "    G = nx.Graph()\n",
    "    neighbour_no = 20\n",
    "    grouped = merfish_data.groupby('Sample')\n",
    "    \n",
    "    # Build graph for each sample\n",
    "    for sample_name, group in grouped:\n",
    "        coords = group[['x', 'y']].values\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        nbrs = NearestNeighbors(n_neighbors=neighbour_no, algorithm='ball_tree').fit(coords)\n",
    "        distances, indices = nbrs.kneighbors(coords)\n",
    "        for i in range(len(coords)):\n",
    "            node_id = group.index[i]\n",
    "            G.add_node(node_id, **group.iloc[i].to_dict())\n",
    "            for j in range(1, neighbour_no):\n",
    "                neighbor_idx = indices[i, j]\n",
    "                neighbor_node_id = group.index[neighbor_idx]\n",
    "                distance = distances[i, j]\n",
    "                G.add_edge(node_id, neighbor_node_id, weight=distance)\n",
    "\n",
    "    nx.set_node_attributes(G, 0, 'Closest_cell_type_label')\n",
    "    for node in G.nodes():\n",
    "        neighbors = sorted(G[node], key=lambda neighbor: G[node][neighbor]['weight'])\n",
    "        if neighbors:\n",
    "            closest_neighbor = neighbors[0]\n",
    "            if G.nodes[closest_neighbor]['Cell_Type'] == cell_type:\n",
    "                G.nodes[node]['Closest_cell_type_label'] = 1\n",
    "\n",
    "    # One-hot encode cell types\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    lb = LabelBinarizer()\n",
    "    unique_labels = list(set(nx.get_node_attributes(G, 'Cell_Type').values()))\n",
    "    lb.fit(unique_labels)\n",
    "    for node in G.nodes():\n",
    "        cell_type_label = G.nodes[node]['Cell_Type']\n",
    "        G.nodes[node]['one_hot_Cell_Type'] = lb.transform([cell_type_label])[0]\n",
    "\n",
    "    # Remove nodes of a particular cell type\n",
    "    G.remove_nodes_from([node for node, data in G.nodes(data=True) if data['Cell_Type'] == cell_type])\n",
    "    \n",
    "    # For each split\n",
    "    for split_num in range(num_splits):\n",
    "        print(f\"Split {split_num + 1} for cell type {cell_type}\")\n",
    "        torch.manual_seed(split_num)\n",
    "        np.random.seed(split_num)\n",
    "        dataset = MouseSpatialPyg(G, merfish_data, edge_lengths=True, inductive_split=True)\n",
    "        data = dataset[0]\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = Net(data, num_features=int(data.num_features), hidden_dim1=16, hidden_dim2=32, dropout_rate=0.5).to(device)\n",
    "        best_performance, best_model, predicted_classes_best_model = train_and_evaluate_model(\n",
    "            model, data, learning_rate=0.001, num_epochs=epoch, weights=True, return_lowest_loss=True\n",
    "        )\n",
    "\n",
    "        ground_truth = data.y[data.test_mask].cpu().numpy()\n",
    "        cell_type_safe = cell_type.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "        probs = torch.exp(predicted_classes_best_model)\n",
    "        roc_auc = binary_auc(probs.cpu().detach().numpy(), ground_truth, data, file_save_name=f\"results/{cell_type_safe}_auc.pdf\")\n",
    "        print(f\"AUC for split {split_num + 1}: {roc_auc}\")\n",
    "        auc_records.append({'Cell_Type': cell_type, 'Split_Num': split_num + 1, 'AUC': roc_auc})\n",
    "        \n",
    "        mask = data['test_mask']\n",
    "        #get indices of true in mask boolean array\n",
    "        indices = [i for i, x in enumerate(mask) if x]\n",
    "        #get class labels for indices (y_pred_class is the predicted output)\n",
    "        _, predict_labels = torch.max(torch.tensor(predicted_classes_best_model), dim=1)\n",
    "        predict_labels=predict_labels.cpu()\n",
    "        test_labels_index = pd.DataFrame({\n",
    "            'Indices': indices,\n",
    "            'Label':  predict_labels\n",
    "        })\n",
    "\n",
    "        score_df_intgrad_aggregated, p_values_df = generate_node_explanations(model, data, test_labels_index, no_explan, mask_type=\"node\", label_list=lb.classes_)\n",
    "        #save\n",
    "        safe_cell_type = str(cell_type).replace(\"/\", \"_\")  # Replace slashes with underscores\n",
    "        #first row= base line, bottom row= node of interest\n",
    "        p_values_df.to_csv(f\"node_{safe_cell_type}_explanations.csv\", index=True)\n",
    "\n",
    "        #edge_explan=generate_edge_explanations(model, data, G, no_explan,cell_type=cell_type)\n",
    "        # Clean up to free memory\n",
    "        del model, data\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Save aggregated AUC records if needed:\n",
    "auc_df = pd.DataFrame(auc_records)\n",
    "auc_df.to_csv(\"results/auc_scores.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View result downstream analysis in figures_paper_gnn.ipynb e.g. plotting node results and edge results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
